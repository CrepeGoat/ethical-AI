## Ethical AI IBM tools


https://lfaidata.foundation/projects/ai-explainability-360/

https://github.com/Trusted-AI/AIX360

### AI Explainability 360
is an open source toolkit that can help users better understand the ways that machine learning models predict labels using a wide variety of techniques throughout the AI application lifecycle.


https://lfaidata.foundation/projects/ai-fairness-360/

https://github.com/Trusted-AI/AIF360

### AI Fairness 360 

is an extensible open source toolkit that can help users understand and mitigate bias in machine learning models throughout the AI application lifecycle.





https://lfaidata.foundation/projects/adversarial-robustness-toolbox/

https://github.com/Trusted-AI/adversarial-robustness-toolbox

https://github.com/Trusted-AI/adversarial-robustness-toolbox/blob/main/notebooks/README.md



https://nbviewer.org/github/Trusted-AI/adversarial-robustness-toolbox/blob/main/notebooks/hugging_face_poisoning.ipynb





### Adversarial Robustness Toolbox (ART) 

provides tools that enable developers and researchers to evaluate, defend, certify and verify Machine Learning models and applications against the adversarial threats.



https://www.ibm.com/docs/en/software-hub/5.2.x?topic=services-ai-factsheets



### With AI Factsheets, 

you can capture essential model details that are required for AI model governance and compliance and track the following metadata across the model development lifecycle:

- Purpose and criticality of the model.
- Measured characteristics of the data set, model, or service.
- Lineage of events and actions that are taken when the model or service is created and deployed



https://www.ibm.com/solutions/zero-trust



### IBM zero trust security strategy 

can help organizations increase their cyber resiliency and manage the risks of a disconnected business environment, while still allowing users access to the appropriate resources.


### MIT Moral Machine

https://www.moralmachine.net/
